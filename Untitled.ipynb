{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "yStart = 1 #starting with col number\n",
    "yEnd = 3 + 1 #19 is actually the number of datasets which I shall make as a dynamic variable or something\n",
    "xStart = 1\n",
    "xEnd = 3+1 #13 is the number of activities you wanna choose\n",
    "\n",
    "#Commented by: James Xi Zheng 12/Aug/2019\n",
    "#please create functions to do the following jobs\n",
    "#1. load dataset ->  sample code availalable in the workshops\n",
    "#2. visualize data -> sample code given\n",
    "#3. remove signal noises -> sample code given\n",
    "#4. extract features -> sample code given\n",
    "#5. prepare training set -> sample code given \n",
    "#6. training the given models -> sample code given\n",
    "#7. test the given models -> sample code given\n",
    "#8. print out the evaluation results -> sample code given\n",
    "\n",
    "#as I said in the lecture, the sample code is completed in a un-professional software engineering style\n",
    "#software refactoring is required\n",
    "#please manage the project using SCRUM sprints and manage the source code using Github\n",
    "#document your progress and think critically what are missing from such IoT application and what are missing to move such IoT application from PoC (proof of concept) to solve real-world life\n",
    "#think with which components added, what kind of real-world problems can be solved by it -> this shall be discussed in the conclusion part in the document\n",
    "\n",
    "#'''\n",
    "#At first, we should explore the raw time-series sensor data. We could draw line plot of sensor signals.\n",
    "#In this example code, the wrist sensor accelerometer data dataset_1 sitting activity is visualized.   \n",
    "#'''\n",
    "#def data_visulization():\n",
    "#    # read dataset file\n",
    "#    df = pd.read_csv('dataset/dataset_1.txt', sep=',', header=None)\n",
    "#    df_sitting = df[df[24] == 1].values\n",
    "#    df.head()\n",
    "    # In this example code, only accelerometer 1 data (column 1 to 3) is used\n",
    "#    plt.plot(df_sitting[:, 0:3])\n",
    "#    plt.show()\n",
    "\n",
    "#'''\n",
    "#For raw sensor data, it usually contains noise that arises from different sources, such as sensor mis-\n",
    "#calibration, sensor errors, errors in sensor placement, or noisy environments. We could apply filter to remove noise of sensor data\n",
    "#to smooth data. In this example code, Butterworth low-pass filter is applied. \n",
    "#'''\n",
    "#def noise_removing():\n",
    "#    df = pd.read_csv('dataset/dataset_1.txt', sep=',', header=None)\n",
    "#    # Butterworth low-pass filter. You could try different parameters and other filters. \n",
    "#    b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "#    df_sitting = df[df[24] == 1].values\n",
    "#   for i in range(3):\n",
    "#       df_sitting[:,i] = signal.lfilter(b, a, df_sitting[:, i])\n",
    "#   plt.plot(df_sitting[15000:20000, 0:3])\n",
    "#   plt.show()\n",
    "\n",
    "\n",
    "#'''\n",
    "#To build a human activity recognition system, we need to extract features from raw data and create feature dataset for training \n",
    "#machine learning models.\n",
    "\n",
    "#Please create new functions to implement your own feature engineering. The function should output training and testing dataset.\n",
    "#'''\n",
    "#def feature_engineering_example():\n",
    "#    training = np.empty(shape=(0, 10))\n",
    "#    testing = np.empty(shape=(0, 10))\n",
    "#    # deal with each dataset file\n",
    "#    for i in range(19):\n",
    "#        df = pd.read_csv('dataset/dataset_' + str(i + 1) + '.txt', sep=',', header=None)\n",
    "#        print('deal with dataset ' + str(i + 1))\n",
    "#        for c in range(1, 14):\n",
    "#           activity_data = df[df[24] == c].values\n",
    "#            b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "#            for j in range(24):\n",
    "#                activity_data[:, j] = signal.lfilter(b, a, activity_data[:, j])\n",
    "#            \n",
    "#            datat_len = len(activity_data)\n",
    "#           training_len = math.floor(datat_len * 0.8)\n",
    "#            training_data = activity_data[:training_len, :]\n",
    "#            testing_data = activity_data[training_len:, :]\n",
    "\n",
    "#            # data segementation: for time series data, we need to segment the whole time series, and then extract features from each period of time\n",
    "#            # to represent the raw data. In this example code, we define each period of time contains 1000 data points. Each period of time contains \n",
    "#            # different data points. You may consider overlap segmentation, which means consecutive two segmentation share a part of data points, to \n",
    "#            # get more feature samples.\n",
    "#            training_sample_number = training_len // 1000 + 1\n",
    "#            testing_sample_number = (datat_len - training_len) // 1000 + 1\n",
    "\n",
    "#            for s in range(training_sample_number):\n",
    "#                if s < training_sample_number - 1:\n",
    "#                    sample_data = training_data[1000*s:1000*(s + 1), :]\n",
    "#                else:\n",
    "#                    sample_data = training_data[1000*s:, :]\n",
    "                # in this example code, only three accelerometer data in wrist sensor is used to extract three simple features: min, max, and mean value in\n",
    "                # a period of time. Finally we get 9 features and 1 label to construct feature dataset. You may consider all sensors' data and extract more\n",
    "\n",
    "#                feature_sample = []\n",
    "#                for i in range(3):\n",
    "#                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "#                    feature_sample.append(np.max(sample_data[:, i]))\n",
    "#                    feature_sample.append(np.mean(sample_data[:, i]))\n",
    "#                feature_sample.append(sample_data[0, -1])\n",
    "#                feature_sample = np.array([feature_sample])\n",
    "#                training = np.concatenate((training, feature_sample), axis=0)\n",
    "            \n",
    "#            for s in range(testing_sample_number):\n",
    "#                if s < training_sample_number - 1:\n",
    "#                    sample_data = testing_data[1000*s:1000*(s + 1), :]\n",
    "#                else:\n",
    "#                    sample_data = testing_data[1000*s:, :]\n",
    "\n",
    "#                feature_sample = []\n",
    "#                for i in range(3):\n",
    "#                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "#                    feature_sample.append(np.max(sample_data[:, i]))\n",
    "#                    feature_sample.append(np.mean(sample_data[:, i]))\n",
    "#                feature_sample.append(sample_data[0, -1])\n",
    "#                feature_sample = np.array([feature_sample])\n",
    "#                testing = np.concatenate((testing, feature_sample), axis=0)\n",
    "\n",
    " #   df_training = pd.DataFrame(training)\n",
    "  #  df_testing = pd.DataFrame(testing)\n",
    "   # df_training.to_csv('training_data.csv', index=None, header=None)\n",
    "    #df_testing.to_csv('testing_data.csv', index=None, header=None)\n",
    "\n",
    "#'''\n",
    "#When we have training and testing feature set, we could build machine learning models to recognize human activities.\n",
    "\n",
    "#Please create new functions to fit your features and try other models.\n",
    "#'''\n",
    "#def model_training_and_evaluation_example():\n",
    "#    df_training = pd.read_csv('training_data.csv', header=None)\n",
    "#    df_testing = pd.read_csv('testing_data.csv', header=None)\n",
    "\n",
    "#    y_train = df_training[9].values\n",
    "    # Labels should start from 0 in sklearn\n",
    "#    y_train = y_train - 1\n",
    "#    df_training = df_training.drop([9], axis=1)\n",
    "#    X_train = df_training.values\n",
    "\n",
    "#    y_test = df_testing[9].values\n",
    "#    y_test = y_test - 1\n",
    "#    df_testing = df_testing.drop([9], axis=1)\n",
    "#    X_test = df_testing.values\n",
    "    \n",
    "    # Feature normalization for improving the performance of machine learning models. In this example code, \n",
    "    # StandardScaler is used to scale original feature to be centered around zero. You could try other normalization methods.\n",
    "#    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "#    X_train = scaler.transform(X_train)\n",
    "#    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Build KNN classifier, in this example code\n",
    "#    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "#    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluation. when we train a machine learning model on training set, we should evaluate its performance on testing set.\n",
    "    # We could evaluate the model by different metrics. Firstly, we could calculate the classification accuracy. In this example\n",
    "    # code, when n_neighbors is set to 4, the accuracy achieves 0.757.\n",
    "#    y_pred = knn.predict(X_test)\n",
    "#    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    # We could use confusion matrix to view the classification for each activity.\n",
    "#    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "\n",
    "    # Another machine learning model: svm. In this example code, we use gridsearch to find the optimial classifier\n",
    "    # It will take a long time to find the optimal classifier.\n",
    "    # the accuracy for SVM classifier with default parameters is 0.71, \n",
    "    # which is worse than KNN. The reason may be parameters of svm classifier are not optimal.  \n",
    "    # Another reason may be we only use 9 features and they are not enough to build a good svm classifier. \n",
    "#    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2, 1e-3, 1e-4],\n",
    "#                     'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 100]},\n",
    "#                    {'kernel': ['linear'], 'C': [1e-3, 1e-2, 1e-1, 1, 10, 100]}]\n",
    "#    acc_scorer = make_scorer(accuracy_score)\n",
    "#    grid_obj  = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring=acc_scorer)\n",
    "#    grid_obj  = grid_obj .fit(X_train, y_train)\n",
    "#    clf = grid_obj.best_estimator_\n",
    "#    print('best clf:', clf)\n",
    "#    clf.fit(X_train, y_train)\n",
    "#    y_pred = clf.predict(X_test)\n",
    "#    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "#    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "# print()\n",
    "# clf = GridSearchCV(SVC(), tuned_parameters, cv=10,\n",
    "#                    scoring=score)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    \n",
    "    # data_visulization()\n",
    "    # noise_removing()\n",
    "    # feature_engineering_example()\n",
    "    #model_training_and_evaluation_example()\n",
    "    \n",
    "#     plt.plot(df_sitting[500:1500, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    for x in range(1, 20):\n",
    "        df = pd.read_csv('daliac/dataset_'+str(x)+'.txt', sep=',', header=None)  # use pandas to read csv file\n",
    "        print( 'Dataset ' + str(x) +' contains %d rows.' % len(df))\n",
    "        print(df.head())# show first 5 rows of the dataset\n",
    "        \n",
    "def data_visualization():\n",
    "    print(\"Visualizing Data in a Graph\")\n",
    "    print(\"\")\n",
    "    daliac_daliac = ['Sitting', 'Lying', 'Standing', 'Washing Dishes', 'Vacuuming', 'Sweeping', 'Walking', 'Ascending Stairs', 'Destending Stairs', 'Treadmill Running', 'Bicycling (50W)', 'Bicycling (100W)', 'Rope Jumping']\n",
    "    # read dataset file\n",
    "    \n",
    "    for y in range(yStart,yEnd):\n",
    "        df = pd.read_csv('daliac/dataset_'+str(y)+'.txt', sep=',', header=None)\n",
    "        for x in range(xStart, xEnd):\n",
    "            print('Person '+ str(y) + ', is '+daliac_daliac[x-1])\n",
    "            df_sitting = df[df[24] == x].values\n",
    "        # In this example code, only accelerometer 1 data (column 1 to 3) is used\n",
    "            plt.plot(df_sitting[:, 0:3])\n",
    "            plt.show()\n",
    "#             plt.plot(df_sitting[:, 3:6])\n",
    "#             plt.show()\n",
    "    print(\"-------------------------------------------------------END------------------------------------------------------\")\n",
    "\n",
    "# def data_visulization():\n",
    "#     # read dataset file\n",
    "#     df = pd.read_csv('daliac/dataset_1.txt', sep=',', header=None)\n",
    "#     df_sitting = df[df[24] == 1].values\n",
    "#     # In this example code, only accelerometer 1 data (column 1 to 3) is used\n",
    "#     plt.plot(df_sitting[:, 0:3])\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "# #     load_dataset()\n",
    "#     data_visulization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probs Noise cancelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removing():\n",
    "    print(\"These are the graphs after noise removal\")\n",
    "    daliac_daliac = ['Sitting', 'Lying', 'Standing', 'Washing Dishes', 'Vacuuming', 'Sweeping', 'Walking', 'Ascending Stairs', 'Destending Stairs', 'Treadmill Running', 'Bicycling (50W)', 'Bicycling (100W)', 'Rope Jumping']\n",
    "    for y in range(1,20):\n",
    "        df = pd.read_csv('daliac/dataset_'+str(y)+'.txt', sep=',', header=None)\n",
    "    # Butterworth low-pass filter. Other filters also include high-pass and 2 others.\n",
    "        for x in range(1, 14):\n",
    "            b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "            print('Person '+ str(y) + ', is '+daliac_daliac[x-1])\n",
    "            df_sitting = df[df[24] == x].values\n",
    "\n",
    "            for i in range(6):\n",
    "                df_sitting[:,i] = signal.lfilter(b, a, df_sitting[:, i])\n",
    "            plt.plot(df_sitting[:, 0:3])\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To build a human activity recognition system, we need to extract features from raw data and create feature dataset for training \n",
    "machine learning models.\n",
    "\n",
    "Please create new functions to implement your own feature engineering. The function should output training and testing dataset.\n",
    "'''\n",
    "def feature_engineering_example():\n",
    "    training = np.empty(shape=(0, 10)) # the same as below\n",
    "    # deal with each dataset file\n",
    "    for i in range(3): #change the value inside to deal with either 1-19 datasets or less OR to deal with specific datasets\n",
    "        df = pd.read_csv('daliac/dataset_' + str(i + 1) + '.txt', sep=',', header=None)\n",
    "        print('deal with dataset ' + str(i + 1))\n",
    "        for c in range(1, 14):\n",
    "            activity_data = df[df[24] == c].values\n",
    "            b, a = signal.butter(4, 0.04, 'low', analog=False)\n",
    "            for j in range(24):\n",
    "                activity_data[:, j] = signal.lfilter(b, a, activity_data[:, j])\n",
    "            \n",
    "            datat_len = len(activity_data) # len(number of rows for this thingy)\n",
    "            training_len = math.floor(datat_len * 0.8) #shows like the round of to minimum or equals value of that integer\n",
    "            training_data = activity_data[:training_len, :] #the same as before\n",
    "\n",
    "            # data segementation: for time series data, we need to segment the whole time series, and then extract features from each period of time\n",
    "            # to represent the raw data. In this example code, we define each period of time contains 1000 data points. Each period of time contains \n",
    "            # different data points. You may consider overlap segmentation, which means consecutive two segmentation share a part of data points, to \n",
    "            # get more feature samples.\n",
    "            training_sample_number = training_len // 1000 + 1\n",
    "            testing_sample_number = (datat_len - training_len) // 1000 + 1\n",
    "\n",
    "#             for s in range(training_sample_number):\n",
    "#                 if s < training_sample_number - 1:\n",
    "#                     sample_data = training_data[1000*s:1000*(s + 1), :]\n",
    "#                 else:\n",
    "#                     sample_data = training_data[1000*s:, :]\n",
    "#                 # in this example code, only three accelerometer data in wrist sensor is used to extract three simple features: min, max, and mean value in\n",
    "#                 # a period of time. Finally we get 9 features and 1 label to construct feature dataset. You may consider all sensors' data and extract more\n",
    "\n",
    "#                 feature_sample = []\n",
    "#                 for i in range(3):\n",
    "#                     feature_sample.append(np.min(sample_data[:, i]))\n",
    "# #                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "# #                     print(np.min(sample_data[:, i]))\n",
    "                    \n",
    "#                     feature_sample.append(np.max(sample_data[:, i]))\n",
    "# #                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "# #                     print(np.max(sample_data[:, i]))\n",
    "                    \n",
    "#                     feature_sample.append(np.mean(sample_data[:, i]))\n",
    "# #                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "# #                     print(np.mean(sample_data[:, i]))\n",
    "                    \n",
    "#                 feature_sample.append(sample_data[0, -1])\n",
    "#                 feature_sample = np.array([feature_sample])\n",
    "#                 training = np.concatenate((training, feature_sample), axis=0)\n",
    "                \n",
    "#         print(\"So This is The Minimum although no idea how I'm gonna parse thru it: \")\n",
    "#         print(np.min(sample_data[:, i]))\n",
    "                \n",
    "#         print(\"So This is The Mean although no idea how I'm gonna parse thru it: \")\n",
    "#         print(np.mean(sample_data[:, i]))\n",
    "                \n",
    "#         print(\"So This is The Max although no idea how I'm gonna parse thru it: \")\n",
    "#         print(np.max(sample_data[:, i]))\n",
    "        \n",
    "#         print(\"Printing np.array([feature_sample])\") \n",
    "#         print(np.array([feature_sample]))\n",
    "#         print(\"Printing training: \") \n",
    "#         print(training)\n",
    "            #code here kinda repeats but testing_sample_number and training_sample_mnumber are the different\n",
    "            for s in range(testing_sample_number):\n",
    "                if s < training_sample_number - 1:\n",
    "                    sample_data = training_data[1000*s:1000*(s + 1), :]\n",
    "                else:\n",
    "                    sample_data = training_data[1000*s:, :]\n",
    "\n",
    "                feature_sample = []\n",
    "                for i in range(3):\n",
    "                    feature_sample.append(np.min(sample_data[:, i]))\n",
    "#                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "#                     print(np.min(sample_data[:, i]))\n",
    "                    feature_sample.append(np.max(sample_data[:, i]))\n",
    "#                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "#                     print(np.max(sample_data[:, i]))\n",
    "                    \n",
    "                    feature_sample.append(np.mean(sample_data[:, i]))\n",
    "#                     print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "#                     print(np.mean(sample_data[:, i]))\n",
    "                \n",
    "#                 print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "#                 print(np.min(sample_data[:, i]))\n",
    "                \n",
    "#                 print(\"So This is The Mean although no idea how I'm gonna parse thru it\")\n",
    "#                 print(np.mean(sample_data[:, i]))\n",
    "                \n",
    "#                 print(\"So This is The Minimum although no idea how I'm gonna parse thru it\")\n",
    "#                 print(np.max(sample_data[:, i]))\n",
    "                \n",
    "                \n",
    "                feature_sample.append(sample_data[0, -1])\n",
    "                feature_sample = np.array([feature_sample])\n",
    "                training = np.concatenate((training, feature_sample), axis=0)\n",
    "                \n",
    "            print(\"For activity \" + str(c))\n",
    "            print(\"This is the data length: \" + str(datat_len))\n",
    "            print(\"This is the training Length: \" + str(training_len))\n",
    "#             print(training_data)\n",
    "\n",
    "            \n",
    "#         print(\"So This is The Minimum although no idea how I'm gonna parse thru it: \" + str(np.min(sample_data[:, i])))\n",
    "# #         print(np.min(sample_data[:, i]))\n",
    "                \n",
    "#         print(\"So This is The Mean although no idea how I'm gonna parse thru it: \" + str(np.mean(sample_data[:, i])))\n",
    "# #         print(np.mean(sample_data[:, i]))\n",
    "                \n",
    "#         print(\"So This is The Max although no idea how I'm gonna parse thru it: \" + str(np.max(sample_data[:, i])))\n",
    "# #         print(np.max(sample_data[:, i]))\n",
    "        \n",
    "\n",
    "    df_training = pd.DataFrame(training)\n",
    "    df_training.to_csv('training_data.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DOWN BELOW IS FOR YOU TO CALL THE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal with dataset 1\n",
      "For activity 1\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24578\n",
      "This is the training Length: 19662\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 18433\n",
      "This is the training Length: 14746\n",
      "For activity 7\n",
      "This is the data length: 52021\n",
      "This is the training Length: 41616\n",
      "For activity 8\n",
      "This is the data length: 6964\n",
      "This is the training Length: 5571\n",
      "For activity 9\n",
      "This is the data length: 6965\n",
      "This is the training Length: 5572\n",
      "For activity 10\n",
      "This is the data length: 25397\n",
      "This is the training Length: 20317\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 13\n",
      "This is the data length: 12907\n",
      "This is the training Length: 10325\n",
      "deal with dataset 2\n",
      "For activity 1\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 2\n",
      "This is the data length: 12904\n",
      "This is the training Length: 10323\n",
      "For activity 3\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 4\n",
      "This is the data length: 24168\n",
      "This is the training Length: 19334\n",
      "For activity 5\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 6\n",
      "This is the data length: 30722\n",
      "This is the training Length: 24577\n",
      "For activity 7\n",
      "This is the data length: 99945\n",
      "This is the training Length: 79956\n",
      "For activity 8\n",
      "This is the data length: 9013\n",
      "This is the training Length: 7210\n",
      "For activity 9\n",
      "This is the data length: 7170\n",
      "This is the training Length: 5736\n",
      "For activity 10\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 11\n",
      "This is the data length: 25192\n",
      "This is the training Length: 20153\n",
      "For activity 12\n",
      "This is the data length: 25191\n",
      "This is the training Length: 20152\n",
      "For activity 13\n",
      "This is the data length: 6356\n",
      "This is the training Length: 5084\n",
      "deal with dataset 3\n",
      "For activity 1\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 15566\n",
      "This is the training Length: 12452\n",
      "For activity 7\n",
      "This is the data length: 55708\n",
      "This is the training Length: 44566\n",
      "For activity 8\n",
      "This is the data length: 9831\n",
      "This is the training Length: 7864\n",
      "For activity 9\n",
      "This is the data length: 7169\n",
      "This is the training Length: 5735\n",
      "For activity 10\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 11\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 12\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 13\n",
      "This is the data length: 9631\n",
      "This is the training Length: 7704\n",
      "deal with dataset 4\n",
      "For activity 1\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 5\n",
      "This is the data length: 13723\n",
      "This is the training Length: 10978\n",
      "For activity 6\n",
      "This is the data length: 20072\n",
      "This is the training Length: 16057\n",
      "For activity 7\n",
      "This is the data length: 50178\n",
      "This is the training Length: 40142\n",
      "For activity 8\n",
      "This is the data length: 10036\n",
      "This is the training Length: 8028\n",
      "For activity 9\n",
      "This is the data length: 8808\n",
      "This is the training Length: 7046\n",
      "For activity 10\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 11\n",
      "This is the data length: 26011\n",
      "This is the training Length: 20808\n",
      "For activity 12\n",
      "This is the data length: 25806\n",
      "This is the training Length: 20644\n",
      "For activity 13\n",
      "This is the data length: 7174\n",
      "This is the training Length: 5739\n",
      "deal with dataset 5\n",
      "For activity 1\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 13108\n",
      "This is the training Length: 10486\n",
      "For activity 6\n",
      "This is the data length: 19867\n",
      "This is the training Length: 15893\n",
      "For activity 7\n",
      "This is the data length: 66972\n",
      "This is the training Length: 53577\n",
      "For activity 8\n",
      "This is the data length: 6350\n",
      "This is the training Length: 5080\n",
      "For activity 9\n",
      "This is the data length: 5121\n",
      "This is the training Length: 4096\n",
      "For activity 10\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 11\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 12\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 13\n",
      "This is the data length: 6560\n",
      "This is the training Length: 5248\n",
      "deal with dataset 6\n",
      "For activity 1\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 6\n",
      "This is the data length: 14542\n",
      "This is the training Length: 11633\n",
      "For activity 7\n",
      "This is the data length: 32361\n",
      "This is the training Length: 25888\n",
      "For activity 8\n",
      "This is the data length: 8398\n",
      "This is the training Length: 6718\n",
      "For activity 9\n",
      "This is the data length: 7784\n",
      "This is the training Length: 6227\n",
      "For activity 10\n",
      "This is the data length: 24986\n",
      "This is the training Length: 19988\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 23963\n",
      "This is the training Length: 19170\n",
      "For activity 13\n",
      "This is the data length: 13933\n",
      "This is the training Length: 11146\n",
      "deal with dataset 7\n",
      "For activity 1\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 6\n",
      "This is the data length: 13313\n",
      "This is the training Length: 10650\n",
      "For activity 7\n",
      "This is the data length: 78850\n",
      "This is the training Length: 63080\n",
      "For activity 8\n",
      "This is the data length: 9217\n",
      "This is the training Length: 7373\n",
      "For activity 9\n",
      "This is the data length: 8193\n",
      "This is the training Length: 6554\n",
      "For activity 10\n",
      "This is the data length: 24578\n",
      "This is the training Length: 19662\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 13\n",
      "This is the data length: 4715\n",
      "This is the training Length: 3772\n",
      "deal with dataset 8\n",
      "For activity 1\n",
      "This is the data length: 12085\n",
      "This is the training Length: 9668\n",
      "For activity 2\n",
      "This is the data length: 11880\n",
      "This is the training Length: 9504\n",
      "For activity 3\n",
      "This is the data length: 11880\n",
      "This is the training Length: 9504\n",
      "For activity 4\n",
      "This is the data length: 26216\n",
      "This is the training Length: 20972\n",
      "For activity 5\n",
      "This is the data length: 11675\n",
      "This is the training Length: 9340\n",
      "For activity 6\n",
      "This is the data length: 22939\n",
      "This is the training Length: 18351\n",
      "For activity 7\n",
      "This is the data length: 41372\n",
      "This is the training Length: 33097\n",
      "For activity 8\n",
      "This is the data length: 7374\n",
      "This is the training Length: 5899\n",
      "For activity 9\n",
      "This is the data length: 5736\n",
      "This is the training Length: 4588\n",
      "For activity 10\n",
      "This is the data length: 23963\n",
      "This is the training Length: 19170\n",
      "For activity 11\n",
      "This is the data length: 25602\n",
      "This is the training Length: 20481\n",
      "For activity 12\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 13\n",
      "This is the data length: 6354\n",
      "This is the training Length: 5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal with dataset 9\n",
      "For activity 1\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 4\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 5\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 6\n",
      "This is the data length: 24986\n",
      "This is the training Length: 19988\n",
      "For activity 7\n",
      "This is the data length: 53046\n",
      "This is the training Length: 42436\n",
      "For activity 8\n",
      "This is the data length: 7374\n",
      "This is the training Length: 5899\n",
      "For activity 9\n",
      "This is the data length: 6555\n",
      "This is the training Length: 5244\n",
      "For activity 10\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 11\n",
      "This is the data length: 25192\n",
      "This is the training Length: 20153\n",
      "For activity 12\n",
      "This is the data length: 25191\n",
      "This is the training Length: 20152\n",
      "For activity 13\n",
      "This is the data length: 7994\n",
      "This is the training Length: 6395\n",
      "deal with dataset 10\n",
      "For activity 1\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 2\n",
      "This is the data length: 12085\n",
      "This is the training Length: 9668\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 16999\n",
      "This is the training Length: 13599\n",
      "For activity 7\n",
      "This is the data length: 49973\n",
      "This is the training Length: 39978\n",
      "For activity 8\n",
      "This is the data length: 9422\n",
      "This is the training Length: 7537\n",
      "For activity 9\n",
      "This is the data length: 8808\n",
      "This is the training Length: 7046\n",
      "For activity 10\n",
      "This is the data length: 24372\n",
      "This is the training Length: 19497\n",
      "For activity 11\n",
      "This is the data length: 24168\n",
      "This is the training Length: 19334\n",
      "For activity 12\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 13\n",
      "This is the data length: 11066\n",
      "This is the training Length: 8852\n",
      "deal with dataset 11\n",
      "For activity 1\n",
      "This is the data length: 11675\n",
      "This is the training Length: 9340\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 11879\n",
      "This is the training Length: 9503\n",
      "For activity 4\n",
      "This is the data length: 24372\n",
      "This is the training Length: 19497\n",
      "For activity 5\n",
      "This is the data length: 11879\n",
      "This is the training Length: 9503\n",
      "For activity 6\n",
      "This is the data length: 17409\n",
      "This is the training Length: 13927\n",
      "For activity 7\n",
      "This is the data length: 55299\n",
      "This is the training Length: 44239\n",
      "For activity 8\n",
      "This is the data length: 9012\n",
      "This is the training Length: 7209\n",
      "For activity 9\n",
      "This is the data length: 7784\n",
      "This is the training Length: 6227\n",
      "For activity 10\n",
      "This is the data length: 23963\n",
      "This is the training Length: 19170\n",
      "For activity 11\n",
      "This is the data length: 24372\n",
      "This is the training Length: 19497\n",
      "For activity 12\n",
      "This is the data length: 24168\n",
      "This is the training Length: 19334\n",
      "For activity 13\n",
      "This is the data length: 6150\n",
      "This is the training Length: 4920\n",
      "deal with dataset 12\n",
      "For activity 1\n",
      "This is the data length: 13314\n",
      "This is the training Length: 10651\n",
      "For activity 2\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 28058\n",
      "This is the training Length: 22446\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 28878\n",
      "This is the training Length: 23102\n",
      "For activity 7\n",
      "This is the data length: 48949\n",
      "This is the training Length: 39159\n",
      "For activity 8\n",
      "This is the data length: 9013\n",
      "This is the training Length: 7210\n",
      "For activity 9\n",
      "This is the data length: 7989\n",
      "This is the training Length: 6391\n",
      "For activity 10\n",
      "This is the data length: 24578\n",
      "This is the training Length: 19662\n",
      "For activity 11\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 12\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 13\n",
      "This is the data length: 7379\n",
      "This is the training Length: 5903\n",
      "deal with dataset 13\n",
      "For activity 1\n",
      "This is the data length: 12085\n",
      "This is the training Length: 9668\n",
      "For activity 2\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 3\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 4\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 16590\n",
      "This is the training Length: 13272\n",
      "For activity 7\n",
      "This is the data length: 59189\n",
      "This is the training Length: 47351\n",
      "For activity 8\n",
      "This is the data length: 7988\n",
      "This is the training Length: 6390\n",
      "For activity 9\n",
      "This is the data length: 7374\n",
      "This is the training Length: 5899\n",
      "For activity 10\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 11\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 12\n",
      "This is the data length: 25806\n",
      "This is the training Length: 20644\n",
      "For activity 13\n",
      "This is the data length: 5740\n",
      "This is the training Length: 4592\n",
      "deal with dataset 14\n",
      "For activity 1\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 5\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 6\n",
      "This is the data length: 15976\n",
      "This is the training Length: 12780\n",
      "For activity 7\n",
      "This is the data length: 58781\n",
      "This is the training Length: 47024\n",
      "For activity 8\n",
      "This is the data length: 8193\n",
      "This is the training Length: 6554\n",
      "For activity 9\n",
      "This is the data length: 7169\n",
      "This is the training Length: 5735\n",
      "For activity 10\n",
      "This is the data length: 24578\n",
      "This is the training Length: 19662\n",
      "For activity 11\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 12\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 13\n",
      "This is the data length: 5535\n",
      "This is the training Length: 4428\n",
      "deal with dataset 15\n",
      "For activity 1\n",
      "This is the data length: 11880\n",
      "This is the training Length: 9504\n",
      "For activity 2\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 3\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 11880\n",
      "This is the training Length: 9504\n",
      "For activity 6\n",
      "This is the data length: 15361\n",
      "This is the training Length: 12288\n",
      "For activity 7\n",
      "This is the data length: 62876\n",
      "This is the training Length: 50300\n",
      "For activity 8\n",
      "This is the data length: 9832\n",
      "This is the training Length: 7865\n",
      "For activity 9\n",
      "This is the data length: 7169\n",
      "This is the training Length: 5735\n",
      "For activity 10\n",
      "This is the data length: 24167\n",
      "This is the training Length: 19333\n",
      "For activity 11\n",
      "This is the data length: 24168\n",
      "This is the training Length: 19334\n",
      "For activity 12\n",
      "This is the data length: 23963\n",
      "This is the training Length: 19170\n",
      "For activity 13\n",
      "This is the data length: 1231\n",
      "This is the training Length: 984\n",
      "deal with dataset 16\n",
      "For activity 1\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 4\n",
      "This is the data length: 32155\n",
      "This is the training Length: 25724\n",
      "For activity 5\n",
      "This is the data length: 11879\n",
      "This is the training Length: 9503\n",
      "For activity 6\n",
      "This is the data length: 18638\n",
      "This is the training Length: 14910\n",
      "For activity 7\n",
      "This is the data length: 60213\n",
      "This is the training Length: 48170\n",
      "For activity 8\n",
      "This is the data length: 7784\n",
      "This is the training Length: 6227\n",
      "For activity 9\n",
      "This is the data length: 6350\n",
      "This is the training Length: 5080\n",
      "For activity 10\n",
      "This is the data length: 24372\n",
      "This is the training Length: 19497\n",
      "For activity 11\n",
      "This is the data length: 25192\n",
      "This is the training Length: 20153\n",
      "For activity 12\n",
      "This is the data length: 24167\n",
      "This is the training Length: 19333\n",
      "For activity 13\n",
      "This is the data length: 7789\n",
      "This is the training Length: 6231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal with dataset 17\n",
      "For activity 1\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 2\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 3\n",
      "This is the data length: 12085\n",
      "This is the training Length: 9668\n",
      "For activity 4\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 5\n",
      "This is the data length: 12290\n",
      "This is the training Length: 9832\n",
      "For activity 6\n",
      "This is the data length: 27444\n",
      "This is the training Length: 21955\n",
      "For activity 7\n",
      "This is the data length: 44444\n",
      "This is the training Length: 35555\n",
      "For activity 8\n",
      "This is the data length: 9626\n",
      "This is the training Length: 7700\n",
      "For activity 9\n",
      "This is the data length: 7988\n",
      "This is the training Length: 6390\n",
      "For activity 10\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 27035\n",
      "This is the training Length: 21628\n",
      "For activity 13\n",
      "This is the data length: 207\n",
      "This is the training Length: 165\n",
      "deal with dataset 18\n",
      "For activity 1\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 2\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 3\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 4\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 5\n",
      "This is the data length: 12494\n",
      "This is the training Length: 9995\n",
      "For activity 6\n",
      "This is the data length: 23963\n",
      "This is the training Length: 19170\n",
      "For activity 7\n",
      "This is the data length: 36047\n",
      "This is the training Length: 28837\n",
      "For activity 8\n",
      "This is the data length: 9422\n",
      "This is the training Length: 7537\n",
      "For activity 9\n",
      "This is the data length: 7988\n",
      "This is the training Length: 6390\n",
      "For activity 10\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 24782\n",
      "This is the training Length: 19825\n",
      "For activity 13\n",
      "This is the data length: 3487\n",
      "This is the training Length: 2789\n",
      "deal with dataset 19\n",
      "For activity 1\n",
      "This is the data length: 11880\n",
      "This is the training Length: 9504\n",
      "For activity 2\n",
      "This is the data length: 12289\n",
      "This is the training Length: 9831\n",
      "For activity 3\n",
      "This is the data length: 11879\n",
      "This is the training Length: 9503\n",
      "For activity 4\n",
      "This is the data length: 24373\n",
      "This is the training Length: 19498\n",
      "For activity 5\n",
      "This is the data length: 12084\n",
      "This is the training Length: 9667\n",
      "For activity 6\n",
      "This is the data length: 17818\n",
      "This is the training Length: 14254\n",
      "For activity 7\n",
      "This is the data length: 40144\n",
      "This is the training Length: 32115\n",
      "For activity 8\n",
      "This is the data length: 8398\n",
      "This is the training Length: 6718\n",
      "For activity 9\n",
      "This is the data length: 7989\n",
      "This is the training Length: 6391\n",
      "For activity 10\n",
      "This is the data length: 24168\n",
      "This is the training Length: 19334\n",
      "For activity 11\n",
      "This is the data length: 24577\n",
      "This is the training Length: 19661\n",
      "For activity 12\n",
      "This is the data length: 24987\n",
      "This is the training Length: 19989\n",
      "For activity 13\n",
      "This is the data length: 10042\n",
      "This is the training Length: 8033\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "#     load_dataset()\n",
    "#     noise_removing()\n",
    "#     data_visualization()\n",
    "    feature_engineering_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
